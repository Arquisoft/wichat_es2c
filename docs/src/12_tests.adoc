== Testing and Monitoring

We implemented a comprehensive testing and monitoring strategy to ensure the stability and
reliability of our project. A wide range of automated tests including unit,
and end-to-end tests were developed to validate the
functionality of each component and to detect potential issues early.
These tests help safeguard the system against regressions when introducing
new features or changes. Additionally, we established continuous
monitoring processes to track system performance and availability in real time,
allowing us to quickly identify and respond to any anomalies.
This proactive approach ensures that our project remains robust, scalable,
and consistently operational.

== Types of Tests Implemented

To guarantee code quality and system reliability, we implemented several types of tests aimed at different layers of the application.
Unit tests were developed using Jest, allowing us to validate individual components and functions in isolation.
These tests contribute significantly to our code coverage, which we continuously track using SonarQube to maintain high standards and detect untested or vulnerable areas.

image:12_coverage.png["Coverage tests"]

In addition to unit testing, we created end-to-end (E2E) tests to simulate
real user interactions and verify that the application behaves correctly from the user’s perspective.
These tests help ensure that critical user flows remain functional across updates.

Their functionality consists of registering a new user, logging in as them, playing a game, asking the chatbot
for hints, then, after the game is done, it checks the user's match history and makes sure the match has been added,
after that it looks at the leaderboard, makes sure its not empty, looks up its own username in it and makes sure the
match also shows up there.

To assess performance and scalability, we also conducted load testing,
which allowed us to evaluate how the system handles high volumes of traffic and to identify potential bottlenecks under stress.

Finally, we used Grafana and Prometheus as monitoring tools to help us detect any outrages in real time.

image:12_grafana.jpg["Grafana load tests"]

Where we can see the average time to process a request for really high numbers of requests per minute.

In addition, we also used oracle monitoring services inside our virtual machine for extra monitoring. (Keep in mind Grafana uses UTC+2 as a timezone, while oracle uses UTC)

image:12_oracle.jpg["Oracle laod tests"]

Which shows the use % of the different components of our server, such as its CPU and memory.


By combining these different types of testing, we’ve built a strong quality assurance framework that minimizes risk and ensures long-term maintainability.